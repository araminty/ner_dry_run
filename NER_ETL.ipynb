{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.util import compounding, minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .tags has the ner labels\n",
    "# en.tok.off has the word positions\n",
    "# they need to be combined to be formatted the way that spacy takes them\n",
    "\n",
    "\n",
    "dirName = \"../gmb-2.2.0/data/\"\n",
    "\n",
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "    for file in filenames:\n",
    "        if \".raw\" in file:\n",
    "            listOfFiles += [os.path.join(dirpath, file)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eccc776ad3248b89ce80b886aadc786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# I want to combine the ner data and position data but discard the rest for now\n",
    "\n",
    "STOP_WORD = \"O\"\n",
    "\n",
    "def get_consecutives(labels, offsets):\n",
    "    \"\"\"Groningen labels each NER token individually while spacy combines them.  This generator gets the indexes\n",
    "    for combining the NER labels\"\"\"\n",
    "    start=end=0\n",
    "    previous=STOP_WORD\n",
    "    while labels:\n",
    "        head = labels.pop(0)\n",
    "        offset = offsets.pop(0).split()\n",
    "        \n",
    "        \n",
    "        if head!=previous and previous!=STOP_WORD:\n",
    "            yield((int(start), int(end), previous))\n",
    "            \n",
    "        if head!=STOP_WORD:\n",
    "            end=offset[1]\n",
    "                \n",
    "        if previous!=head!=STOP_WORD:\n",
    "            start=offset[0]\n",
    "        previous=head\n",
    "    \n",
    "\n",
    "TRAIN_DATA = list()\n",
    "\n",
    "for raw_file in tqdm(listOfFiles):\n",
    "    with open(raw_file) as raw_text_file:\n",
    "        text = raw_text_file.read().replace('\\n', ' ')\n",
    "        \n",
    "    tag_file = \"../\"+raw_file.strip(\".raw\")+\".tags\"\n",
    "    with open(tag_file) as tag_data:\n",
    "        tags_by_line = tag_data.readlines()\n",
    "        ner_labels = [ line.split(\"\\t\")[3] for line in tags_by_line if len(line.split(\"\\t\"))>2 ]\n",
    "        \n",
    "    offsets_file = \"../\"+raw_file.strip(\".raw\") + \".tok.off\"\n",
    "    with open(offsets_file) as offsets_file:\n",
    "        offsets = offsets_file.readlines()\n",
    "\n",
    "    TRAIN_DATA.append((text, list(get_consecutives(ner_labels, offsets))))\n",
    "    \n",
    "NER_LABELS = set(ner[2] for line in TRAIN_DATA  for ner in line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ner</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>per-giv</td>\n",
       "      <td>Benedict</td>\n",
       "      <td>0</td>\n",
       "      <td>Pope Benedict XVI has visited the Italian city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>per-nam</td>\n",
       "      <td>XVI</td>\n",
       "      <td>0</td>\n",
       "      <td>Pope Benedict XVI has visited the Italian city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>gpe-nam</td>\n",
       "      <td>Italian</td>\n",
       "      <td>0</td>\n",
       "      <td>Pope Benedict XVI has visited the Italian city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>geo-nam</td>\n",
       "      <td>L'Aquilla</td>\n",
       "      <td>0</td>\n",
       "      <td>Pope Benedict XVI has visited the Italian city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>gpe-nam</td>\n",
       "      <td>Italian</td>\n",
       "      <td>0</td>\n",
       "      <td>Pope Benedict XVI has visited the Italian city...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label        ner  paragraph_index  \\\n",
       "0  per-giv   Benedict                0   \n",
       "1  per-nam        XVI                0   \n",
       "2  gpe-nam    Italian                0   \n",
       "3  geo-nam  L'Aquilla                0   \n",
       "4  gpe-nam    Italian                0   \n",
       "\n",
       "                                           paragraph  \n",
       "0  Pope Benedict XVI has visited the Italian city...  \n",
       "1  Pope Benedict XVI has visited the Italian city...  \n",
       "2  Pope Benedict XVI has visited the Italian city...  \n",
       "3  Pope Benedict XVI has visited the Italian city...  \n",
       "4  Pope Benedict XVI has visited the Italian city...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "geo-nam    48866\n",
       "org-nam    26190\n",
       "gpe-nam    20434\n",
       "per-nam    14962\n",
       "tim-dow    11401\n",
       "tim-dat     9662\n",
       "per-tit     9163\n",
       "per-fam     8044\n",
       "tim-yoc     5287\n",
       "tim-moy     4261\n",
       "per-giv     2341\n",
       "tim-clo      726\n",
       "art-nam      501\n",
       "eve-nam      290\n",
       "nat-nam      238\n",
       "tim-nam      134\n",
       "eve-ord      107\n",
       "org-leg       59\n",
       "per-ini       55\n",
       "per-ord       38\n",
       "tim-dom       10\n",
       "art-add        1\n",
       "per-mid        1\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def DF_generator(DATA):\n",
    "    for i, line in enumerate(DATA):\n",
    "        for ner in line[1]:\n",
    "            yield ner[2], line[0][ner[0]:ner[1]], i, line[0]\n",
    "\n",
    "df = pd.DataFrame(DF_generator(TRAIN_DATA), columns=['label', 'ner', 'paragraph_index', 'paragraph'])\n",
    "\n",
    "display(df.head())\n",
    "display(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "\n",
    "tallies = df.label.value_counts()\n",
    "included_labels = tallies[tallies>5000]\n",
    "for label in included_labels.index:\n",
    "    ner.add_label(label)\n",
    "\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "def trimmer(train_data, keep):\n",
    "    \n",
    "    for line in train_data:\n",
    "        paragraph = line[0]\n",
    "        ners = [match for match in line[1] if match[2] in keep]\n",
    "        yield(paragraph, {\"entities\": ners})\n",
    "\n",
    "\n",
    "train_data = list(trimmer(TRAIN_DATA[:], list(included_labels.index)))\n",
    "train_data, holdout_data = train_test_split(train_data, train_size=0.6)\n",
    "train_data, test_data = train_test_split(train_data, train_size=0.6)\n",
    "\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = compounding(1.0, 4.0, 1.001)\n",
    "iterations = tqdm(range(15), position=0)\n",
    "for _ in iterations:\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=sizes)\n",
    "    losses = {}\n",
    "    inner_loop = tqdm(list(batches), leave=False, position=1)\n",
    "    for batch in inner_loop:\n",
    "        text, annotations = zip(*batch)\n",
    "        nlp.update(text, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "    iterations.set_description(\"Loss: \" + str([round(value,2) for value in losses.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.to_disk(\"./exported_model\")\n",
    "\n",
    "nlp = nlp.from_disk(\"./exported_model\")\n",
    "optimizer = nlp.resume_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_evaluation(model, test_data):\n",
    "    label_tp = label_fp = label_fn = phrase_tp = phrase_fp = phrase_fn = 0\n",
    "    \n",
    "    true_p = 0\n",
    "    false_p = 0\n",
    "    false_n = 0\n",
    "    \n",
    "    for test in tqdm(test_data):\n",
    "        text = test[0]\n",
    "        ners = test[1]['entities']\n",
    "        true_phrases = [text[ner[0]:ner[1]] for ner in ners]\n",
    "        true_labels = [ner[2] for ner in ners]\n",
    "        \n",
    "        found_phrases = [ ent.text for ent in model(text).ents ]\n",
    "        found_labels = [ ent.label_ for ent in model(text).ents ]\n",
    "        correct = [ner[2] for ner in ners]\n",
    "        \n",
    "        for phrase in found_phrases:\n",
    "            if phrase in true_phrases:\n",
    "                phrase_tp += 1\n",
    "            else:\n",
    "                phrase_fp += 1\n",
    "        \n",
    "        for phrase in found_phrases:\n",
    "            if phrase not in found_phrases:\n",
    "                phrase_fn += 0\n",
    "            \n",
    "        for ent in found_labels:\n",
    "            if ent in true_labels:\n",
    "                label_tp += 1\n",
    "            else:\n",
    "                label_fp += 1\n",
    "        \n",
    "        for ner in true_labels:\n",
    "            if ner not in found_labels:\n",
    "                label_fn += 0\n",
    "            \n",
    "    results = {}\n",
    "    \n",
    "    results['phrase_precision'] = phrase_tp / (phrase_tp + phrase_fp)\n",
    "    results['phrase_recall'] = phrase_tp / (phrase_tp + phrase_fn)\n",
    "    results['label_precision'] = label_tp / (label_tp + label_fp)\n",
    "    results['label_recall'] = label_tp / (label_tp + label_fn)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83529fc8b8b47f79380321b020d7d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_evaluation(nlp, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
